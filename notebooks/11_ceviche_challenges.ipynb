{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Integration with ceviche challenges to test the optimization\n",
    "output-file: ceviche_challenges.html\n",
    "title: Ceviche Challenges\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ceviche_challenges\n",
    "from ceviche_challenges import units as u\n",
    "import ceviche\n",
    "from inverse_design.brushes import notched_square_brush, circular_brush\n",
    "from inverse_design.conditional_generator import (\n",
    "    new_latent_design, transform\n",
    ")\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import autograd\n",
    "import autograd.numpy as npa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from javiche import jaxit\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from inverse_design.local_generator import generate_feasible_design_mask\n",
    "from jax.example_libraries.optimizers import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = ceviche_challenges.waveguide_bend.prefabs.waveguide_bend_2umx2um_spec(\n",
    "  wg_width=400*u.nm, variable_region_size=(1600*u.nm, 1600*u.nm), cladding_permittivity=2.25\n",
    ")\n",
    "params = ceviche_challenges.waveguide_bend.prefabs.waveguide_bend_sim_params(resolution = 25 * u.nm)\n",
    "model = ceviche_challenges.waveguide_bend.model.WaveguideBendModel(params, spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(latent_weights, brush):\n",
    "    latent_t = transform(latent_weights, brush) #.reshape((Nx, Ny))\n",
    "    design_mask = generate_feasible_design_mask(latent_t, \n",
    "      brush, verbose=False)\n",
    "    design = (design_mask+1.0)/2.0\n",
    "    return design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brush = circular_brush(5)\n",
    "latent = new_latent_design(model.design_variable_shape, bias=0.5, r=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jaxit(cache=True)\n",
    "def inner_loss_fn(design):\n",
    "    s_params, fields = model.simulate(design)\n",
    "    s11 = npa.abs(s_params[:, 0, 0])\n",
    "    s21 = npa.abs(s_params[:, 0, 1])\n",
    "    \n",
    "    global debug_fields\n",
    "    debug_fields = fields\n",
    "    global debug_design\n",
    "    debug_design = design\n",
    "    global debug_flag # indicates forward run\n",
    "    debug_flag = isinstance(design, np.ndarray)\n",
    "\n",
    "    return npa.mean(s11) - npa.mean(s21)\n",
    "\n",
    "def loss_fn(latent):\n",
    "    design = forward(latent, brush)\n",
    "    return inner_loss_fn(design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs in the optimization\n",
    "Nsteps = 150\n",
    "# Step size for the Adam optimizer\n",
    "# def step_size(idx):\n",
    "#   \"\"\"reducing the stepsize linearly for Nsteps (stabilize afterwards just in case)\"\"\"\n",
    "#   start = 0.1\n",
    "#   stop = 5e-3\n",
    "#   return start*(stop/start)**(idx/Nsteps)\n",
    "\n",
    "step_size = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent(latent):\n",
    "  global debug_design, debug_fields, debug_flag\n",
    "  design = forward(latent, brush)\n",
    "  s_params, fields = model.simulate(design)\n",
    "  debug_design = design\n",
    "  debug_fields = fields\n",
    "  debug_flag = True\n",
    "  visualize_debug()\n",
    "\n",
    "def visualize_debug():\n",
    "  global debug_design, debug_fields, debug_flag\n",
    "  if debug_flag:\n",
    "    debug_flag = False\n",
    "  else:\n",
    "    return\n",
    "    \n",
    "  if not isinstance(debug_fields, np.ndarray):\n",
    "    debug_fields = debug_fields._value\n",
    "    debug_design = debug_design._value\n",
    "  ceviche.viz.abs(np.squeeze(np.asarray(debug_fields)), model.density(np.asarray(debug_design)))\n",
    "  plt.grid()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_fn = jax.grad(loss_fn)\n",
    "\n",
    "init_fn, update_fn, params_fn = adam(step_size)\n",
    "state = init_fn(latent) #.flatten()\n",
    "#value_and_grad seems to have a problem. Figure out why!\n",
    "\n",
    "def step_fn(step, state):\n",
    "    latent = params_fn(state) # we need autograd arrays here...\n",
    "    grads = grad_fn(latent)\n",
    "    loss = loss_fn(latent)\n",
    "    #loss = loss_fn(latent)\n",
    "\n",
    "    optim_state = update_fn(step, grads, state)\n",
    "    # optim_latent = params_fn(optim_state)\n",
    "    # optim_latent = optim_latent/optim_latent.std()\n",
    "\n",
    "    visualize_debug()\n",
    "    return loss, optim_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = params_fn(state)\n",
    "visualize_latent(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval:false\n",
    "range_ = trange(Nsteps)\n",
    "losses = np.ndarray(Nsteps)\n",
    "for step in range_:\n",
    "    loss, state = step_fn(step, state)\n",
    "    losses[step] = loss\n",
    "    range_.set_postfix(loss=float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = params_fn(state)\n",
    "design = forward(latent, brush)\n",
    "s_params, fields = model.simulate(design)\n",
    "epsr = model.epsilon_r(design)\n",
    "ceviche.viz.abs(np.squeeze(fields), model.density(design))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "y",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
